{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/research/data/zhenyang/openpi/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "import dataclasses\n",
                "\n",
                "import jax\n",
                "\n",
                "from openpi.models import model as _model\n",
                "from openpi.policies import droid_policy\n",
                "from openpi.policies import policy_config as _policy_config\n",
                "from openpi.shared import download\n",
                "from openpi.training import config as _config\n",
                "from openpi.training import data_loader as _data_loader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Policy inference\n",
                "\n",
                "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "'observation/image'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\u001b[39;00m\n\u001b[32m      9\u001b[39m example = droid_policy.make_droid_example()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Delete the policy to free up memory.\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m policy\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/policies/policy.py:71\u001b[39m, in \u001b[36mPolicy.infer\u001b[39m\u001b[34m(self, obs, noise)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: \u001b[38;5;28mdict\u001b[39m, *, noise: np.ndarray | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mdict\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Make a copy since transformations may modify the inputs in place.\u001b[39;00m\n\u001b[32m     70\u001b[39m     inputs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x, obs)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_pytorch_model:\n\u001b[32m     73\u001b[39m         \u001b[38;5;66;03m# Make a batch and convert to jax.Array.\u001b[39;00m\n\u001b[32m     74\u001b[39m         inputs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp.asarray(x)[np.newaxis, ...], inputs)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/transforms.py:70\u001b[39m, in \u001b[36mCompositeTransform.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DataDict) -> DataDict:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         data = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/policies/libero_policy.py:52\u001b[39m, in \u001b[36mLiberoInputs.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Possibly need to parse images to uint8 (H,W,C) since LeRobot automatically\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# stores as float32 (C,H,W), gets skipped for policy inference.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# of image, e.g. wrist images, you can comment it out here and replace it with zeros like we do for the\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# right wrist image below.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     base_image = _parse_image(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobservation/image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     53\u001b[39m     wrist_image = _parse_image(data[\u001b[33m\"\u001b[39m\u001b[33mobservation/wrist_image\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Create inputs dict. Do not change the keys in the dict below.\u001b[39;00m\n",
                        "\u001b[31mKeyError\u001b[39m: 'observation/image'"
                    ]
                }
            ],
            "source": [
                "# config = _config.get_config(\"pi0_fast_droid\")\n",
                "config = _config.get_config(\"pi05_libero\")\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi05_libero\")       \n",
                "\n",
                "# Create a trained policy.\n",
                "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "\n",
                "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
                "example = droid_policy.make_droid_example()\n",
                "result = policy.infer(example)\n",
                "\n",
                "# Delete the policy to free up memory.\n",
                "del policy\n",
                "\n",
                "print(\"Actions shape:\", result[\"actions\"].shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "test: dict_keys(['observation/exterior_image_1_left', 'observation/wrist_image_left', 'observation/joint_position', 'observation/gripper_position', 'prompt', 'observation/state', 'observation/image', 'observation/wrist_image'])\n"
                    ]
                },
                {
                    "ename": "EinopsError",
                    "evalue": " Error while processing rearrange-reduction pattern \"c h w -> h w c\".\n Input tensor shape: (3, 224, 224, 3). Additional info: {}.\n Wrong shape: expected 3 dims. Received 4-dim tensor.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mEinopsError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/.venv/lib/python3.11/site-packages/einops/einops.py:531\u001b[39m, in \u001b[36mreduce\u001b[39m\u001b[34m(tensor, pattern, reduction, **axes_lengths)\u001b[39m\n\u001b[32m    530\u001b[39m shape = backend.shape(tensor)\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m recipe = \u001b[43m_prepare_transformation_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_names\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_recipe(\n\u001b[32m    533\u001b[39m     backend, recipe, cast(Tensor, tensor), reduction_type=reduction, axes_lengths=hashable_axes_lengths\n\u001b[32m    534\u001b[39m )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/.venv/lib/python3.11/site-packages/einops/einops.py:366\u001b[39m, in \u001b[36m_prepare_transformation_recipe\u001b[39m\u001b[34m(pattern, operation, axes_names, ndim)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ndim != \u001b[38;5;28mlen\u001b[39m(left.composition):\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWrong shape: expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(left.composition)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dims. Received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-dim tensor.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    367\u001b[39m left_composition = left.composition\n",
                        "\u001b[31mEinopsError\u001b[39m: Wrong shape: expected 3 dims. Received 4-dim tensor.",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[31mEinopsError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m example[\u001b[33m'\u001b[39m\u001b[33mobservation/wrist_image\u001b[39m\u001b[33m'\u001b[39m] = jax.numpy.repeat(example[\u001b[33m'\u001b[39m\u001b[33mobservation/wrist_image_left\u001b[39m\u001b[33m'\u001b[39m][\u001b[38;5;28;01mNone\u001b[39;00m], \u001b[32m3\u001b[39m, axis=\u001b[32m0\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample.keys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/policies/policy.py:71\u001b[39m, in \u001b[36mPolicy.infer\u001b[39m\u001b[34m(self, obs, noise)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: \u001b[38;5;28mdict\u001b[39m, *, noise: np.ndarray | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mdict\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Make a copy since transformations may modify the inputs in place.\u001b[39;00m\n\u001b[32m     70\u001b[39m     inputs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x, obs)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_pytorch_model:\n\u001b[32m     73\u001b[39m         \u001b[38;5;66;03m# Make a batch and convert to jax.Array.\u001b[39;00m\n\u001b[32m     74\u001b[39m         inputs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp.asarray(x)[np.newaxis, ...], inputs)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/transforms.py:70\u001b[39m, in \u001b[36mCompositeTransform.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DataDict) -> DataDict:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         data = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/policies/libero_policy.py:52\u001b[39m, in \u001b[36mLiberoInputs.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Possibly need to parse images to uint8 (H,W,C) since LeRobot automatically\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# stores as float32 (C,H,W), gets skipped for policy inference.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# of image, e.g. wrist images, you can comment it out here and replace it with zeros like we do for the\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# right wrist image below.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     base_image = \u001b[43m_parse_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobservation/image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     wrist_image = _parse_image(data[\u001b[33m\"\u001b[39m\u001b[33mobservation/wrist_image\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Create inputs dict. Do not change the keys in the dict below.\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/src/openpi/policies/libero_policy.py:25\u001b[39m, in \u001b[36m_parse_image\u001b[39m\u001b[34m(image)\u001b[39m\n\u001b[32m     23\u001b[39m     image = (\u001b[32m255\u001b[39m * image).astype(np.uint8)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.shape[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     image = \u001b[43meinops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mc h w -> h w c\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/.venv/lib/python3.11/site-packages/einops/einops.py:600\u001b[39m, in \u001b[36mrearrange\u001b[39m\u001b[34m(tensor, pattern, **axes_lengths)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, **axes_lengths: Size) -> Tensor:\n\u001b[32m    546\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[33;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[33;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \n\u001b[32m    599\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrearrange\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/research/data/zhenyang/openpi/.venv/lib/python3.11/site-packages/einops/einops.py:542\u001b[39m, in \u001b[36mreduce\u001b[39m\u001b[34m(tensor, pattern, reduction, **axes_lengths)\u001b[39m\n\u001b[32m    540\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Input is list. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m message += \u001b[33m\"\u001b[39m\u001b[33mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(axes_lengths)\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(e))\n",
                        "\u001b[31mEinopsError\u001b[39m:  Error while processing rearrange-reduction pattern \"c h w -> h w c\".\n Input tensor shape: (3, 224, 224, 3). Additional info: {}.\n Wrong shape: expected 3 dims. Received 4-dim tensor."
                    ]
                }
            ],
            "source": [
                "example = droid_policy.make_droid_example()\n",
                "example['observation/state'] = jax.numpy.zeros((3, 7))\n",
                "example['observation/image'] = jax.numpy.repeat(example['observation/exterior_image_1_left'][None], 3, axis=0)\n",
                "example['observation/wrist_image'] = jax.numpy.repeat(example['observation/wrist_image_left'][None], 3, axis=0)\n",
                "print(f\"test: {example.keys()}\")\n",
                "\n",
                "result = policy.infer(example)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Actions shape: (10, 7)\n",
                        "example['observation/image'] shape: (224, 224, 3)\n"
                    ]
                }
            ],
            "source": [
                "print(\"Actions shape:\", result[\"actions\"].shape)\n",
                "print(f\"example['observation/image'] shape: {example['observation/image'].shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'policy' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mpolicy\u001b[49m\n",
                        "\u001b[31mNameError\u001b[39m: name 'policy' is not defined"
                    ]
                }
            ],
            "source": [
                "del policy"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with a live model\n",
                "\n",
                "\n",
                "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = _config.get_config(\"pi0_aloha_sim\")\n",
                "\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_aloha_sim\")\n",
                "key = jax.random.key(0)\n",
                "\n",
                "# Create a model from the checkpoint.\n",
                "model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
                "\n",
                "# We can create fake observations and actions to test the model.\n",
                "obs, act = config.model.fake_obs(), config.model.fake_act()\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reduce the batch size to reduce memory usage.\n",
                "config = dataclasses.replace(config, batch_size=2)\n",
                "\n",
                "# Load a single batch of data. This is the same data that will be used during training.\n",
                "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
                "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
                "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
                "obs, act = next(iter(loader))\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "\n",
                "# Delete the model to free up memory.\n",
                "del model\n",
                "\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
